{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from copy import deepcopy\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from typing import Optional, Any, defaultdict\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables\n"
     ]
    }
   ],
   "source": [
    "def load_env():\n",
    "\tenv_file_path = \".env\"\n",
    "\tif os.path.exists(env_file_path):\n",
    "\t\tload_dotenv(env_file_path, override=True)\n",
    "\t\tprint(\"Loaded environment variables\")\n",
    "\telse:\n",
    "\t\tprint(f\"Error: .env file not found at {env_file_path}\")\n",
    "\n",
    "load_env()\n",
    "\n",
    "class ModelSettings(BaseSettings):\n",
    "\tmodel: str\n",
    "\ttemperature: Optional[float] = 0\n",
    "\tmax_tokens: Optional[int] = None\n",
    "\n",
    "class ProcessModelSettings(BaseSettings):\n",
    "\tembedding: ModelSettings\n",
    "\tgpt4o: ModelSettings\n",
    "\tphi4: ModelSettings\n",
    "\tdeepseek: ModelSettings\n",
    "\to1: ModelSettings\n",
    "\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "\tmodel_config = SettingsConfigDict(env_file=\".env\", env_nested_delimiter=\"__\")\n",
    "\n",
    "\t# Keys\n",
    "\tazure_openai_api_key: Optional[str]\n",
    "\tazure_openai_endpoint: Optional[str]\n",
    "\topenai_api_version: Optional[str]\n",
    "\n",
    "\topenai_api_deployment_name_gpt4_vision_no_filters: Optional[str]\n",
    "\topenai_vision_api_version_gpt4_vision_no_filters: Optional[str]\n",
    "\topenai_api_key_gpt4_vision_no_filters: Optional[str]\n",
    "\topenai_base_url_gpt4_vision_no_filters: Optional[str]\n",
    "\n",
    "\t# models\n",
    "\tprocessmodel: ProcessModelSettings\n",
    "\t\n",
    "\n",
    "settings = Settings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract information headers from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chapter_title(content):\n",
    "\tpattern = r\"^#\\s*(.+)$\"\n",
    "\tfor i, line in enumerate(content.split(\"\\n\"), start=1):\n",
    "\t\tmatch = re.match(pattern, line)\n",
    "\t\tif match:\n",
    "\t\t\treturn match.group(1).strip()\n",
    "\treturn \"\"\n",
    "\n",
    "def extract_sections_list(content):\n",
    "\tpattern = r'(^## (?!#).*?(?=^## (?!#)|\\Z))'\n",
    "\tsections = re.findall(pattern, content, flags=re.MULTILINE | re.DOTALL)\n",
    "\tsection_list = []\n",
    "\tfor sec in sections:\n",
    "\t\tsec = sec.strip()\n",
    "\t\tlines = sec.splitlines()\n",
    "\t\tif lines:\n",
    "\t\t\theader = lines[0][3:].strip()  # Remove \"## \" prefix\n",
    "\t\t\tbody = \"\\n\".join(lines[1:]).strip()\n",
    "\t\t\tsection_list.append((header, body))  # Store as a tuple\n",
    "\treturn section_list\n",
    "\n",
    "\n",
    "def RAG_extract_criteria_advices(text):\n",
    "\n",
    "\tadvice_pattern = r\"###\\s*(?:Advice\\s*)?(\\d+)\\.\\s*([^\\n]+)\\s*([\\s\\S]+?)(?=###\\s*(?:Advice\\s*)?\\d+\\.|\\Z)\"\n",
    "\tmatches = re.findall(advice_pattern, text)\n",
    "\tAdvices = {}\n",
    "\n",
    "\tsep = \"\\n\"\n",
    "\tfor i, match in enumerate(matches):\n",
    "\t\tadvice_number = int(match[0].strip())\n",
    "\t\tadvice_title = f\"{sep}Advice {match[0].strip()}. {match[1].strip()}\\n\"\n",
    "\t\tAdvices[advice_number] = advice_title + match[2].strip()\n",
    "\n",
    "\tcriteria_pattern = r\"^-\\s*(Critical|Urgent|Normal)\\s*\\|\\s*([^|\\n]+)(?:\\|\\s*([^|\\n]+))?$\"\n",
    "\tmatches = re.findall(criteria_pattern, text, flags=re.MULTILINE)\n",
    "\tcriteria_list = []\n",
    "\tfor severity, criteria, advice_codes in matches:\n",
    "\t\tseverity = severity.strip()\n",
    "\t\tcriteria = criteria.strip()\n",
    "\n",
    "\t\tadvice_list = []\n",
    "\t\tfor advice_code in map(str.strip, advice_codes.split(\".\")):\n",
    "\n",
    "\t\t\tif advice_code == \"\":\n",
    "\t\t\t\tprint(f\"Empty advice code found in criteria: {criteria}\")\n",
    "\t\t\t\tprint(f\"text: {text}\")\n",
    "\t\t\t\traise ValueError(\"Advice code is empty\")\n",
    "\n",
    "\t\t\tif not advice_code:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\ttry:\n",
    "\t\t\t\tadvice_number = int(advice_code)\n",
    "\t\t\t\tif advice_number in Advices:\n",
    "\t\t\t\t\tadvice_list.append(Advices[advice_number])\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\tadvice_list.append(f\"- No specific emergency advices are given, note: ({advice_code}).\")\n",
    "\n",
    "\t\t# Remove useless criteria/advices\n",
    "\t\tif \"other, not urgent\" in criteria.lower() or \"other symptoms related to this page\" in criteria.lower() or not advice_list:\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\tcriteria_list.append({\n",
    "\t\t\t\"severity\": severity,\n",
    "\t\t\t\"criteria\": criteria,\n",
    "\t\t\t\"advice_list\": advice_list\n",
    "\t\t})\n",
    "\n",
    "\treturn criteria_list\n",
    "\n",
    "\n",
    "\n",
    "def TRAIN_get_criteria_advices(text):\n",
    "\n",
    "\tadvice_pattern = r\"###\\s*(?:Advice\\s*)?(\\d+)\\.\\s*([^\\n]+)\\s*([\\s\\S]+?)(?=###\\s*(?:Advice\\s*)?\\d+\\.|\\Z)\"\n",
    "\tmatches = re.findall(advice_pattern, text)\n",
    "\tAdvices = {}\n",
    "\n",
    "\tsep = \"\\n\"\n",
    "\tfor i, match in enumerate(matches):\n",
    "\t\tadvice_number = int(match[0].strip())\n",
    "\t\tadvice_title = f\"{sep}Advice {match[0].strip()}. {match[1].strip()}\\n\"\n",
    "\t\tAdvices[advice_number] = advice_title + match[2].strip()\n",
    "\n",
    "\tcriteria_pattern = r\"^-\\s*(Critical|Urgent|Normal)\\s*\\|\\s*([^|\\n]+)(?:\\|\\s*([^|\\n]+))?$\"\n",
    "\tmatches = re.findall(criteria_pattern, text, flags=re.MULTILINE)\n",
    "\tcriteria_list = []\n",
    "\tfor severity, criteria, advice_codes in matches:\n",
    "\t\tseverity = severity.strip()\n",
    "\t\tcriteria = criteria.strip()\n",
    "\n",
    "\t\tadvice_list = []\n",
    "\t\tfor advice_code in map(str.strip, advice_codes.split(\".\")):  \n",
    "\n",
    "\t\t\tif not advice_code:\n",
    "\t\t\t\tcontinue  \n",
    "\t\t\ttry:\n",
    "\t\t\t\tadvice_number = int(advice_code)\n",
    "\t\t\t\tif advice_number in Advices:\n",
    "\t\t\t\t\tadvice_list.append(Advices[advice_number])\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t# Remove useless criteria/advices\n",
    "\t\tif \"other, not urgent\" in criteria.lower() or \"other symptoms related to this page\" in criteria.lower() or not advice_list:\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\tcriteria_list.append({\n",
    "\t\t\t\"severity\": severity,\n",
    "\t\t\t\"criteria\": criteria,\n",
    "\t\t\t\"advice_list\": advice_list\n",
    "\t\t})\n",
    "\n",
    "\treturn criteria_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract criteria and advices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractData():\n",
    "\tdef __init__(self, file_path):\n",
    "\t\tself.file_path = file_path\n",
    "\t\tself.base_name = Path(file_path).stem\n",
    "\t\tself.formatted_data = []\n",
    "\t\tself.categorized_data = {\n",
    "\t\t\t\"Criteria\": [],\n",
    "\t\t\t\"Scenario\": [],\n",
    "\t\t\t\"Other\": []\n",
    "\t\t}\n",
    "\n",
    "\tdef extract_critiera(self, chapter, section_text):\n",
    "\t\tcriteria_list = RAG_extract_criteria_advices(section_text)\n",
    "\t\tfor i, entry in enumerate(criteria_list):\n",
    "\t\t\tcriteria = entry[\"criteria\"]\n",
    "\t\t\tadvices = \"\\n\".join(entry[\"advice_list\"])\n",
    "\t\t\tself.categorized_data[\"Criteria\"].append({\"criteria\": criteria, \"advices\": advices, \"chapter\": chapter})\n",
    "\t\t\t\t\t  \n",
    "\tdef extract_scenario(self, chapter, section_text):\n",
    "\t\tscenario_match = re.search(r\"### SCENARIO\\s*(.*?)(?=\\n###|\\n##|\\n#|$)\", section_text, re.DOTALL)\n",
    "\n",
    "\t\t# Improved regex to handle spaces and stop at the next section (##, ###, or #)\n",
    "\t\tif_yes_match = re.search(r\"### IF YES\\s*(.*?)(?=\\n###|\\n##|\\n#|$)\", section_text, re.DOTALL)\n",
    "\t\tif_no_match = re.search(r\"### IF NO\\s*(.*?)(?=\\n###|\\n##|\\n#|$)\", section_text, re.DOTALL)\n",
    "\n",
    "\t\tif_yes_content = if_yes_match.group(1).strip() if if_yes_match else None\n",
    "\t\tif_no_content = if_no_match.group(1).strip() if if_no_match else None\n",
    "\t\tscenario_content = scenario_match.group(1).strip() if scenario_match else None\n",
    "\n",
    "\t\tscenario_content = scenario_content.lower().replace(\"\\n\", \", \").replace(\"-\", \"\").strip()\n",
    "\t\tscenario_content = \" \".join(scenario_content.split())\n",
    "\n",
    "\t\tif not scenario_content:\n",
    "\t\t\traise Exception(\"No scenario content found\")\n",
    "\t\t\n",
    "\t\tif if_yes_content:\n",
    "\t\t\tself.categorized_data[\"Scenario\"].append({\"criteria\": scenario_content + \" (IF YES)\", \"advices\": if_yes_content, \"chapter\": chapter})\n",
    "\n",
    "\t\tif if_no_content:\n",
    "\t\t\tself.categorized_data[\"Scenario\"].append({\"criteria\": scenario_content + \" (IF NO)\", \"advices\": if_no_content, \"chapter\": chapter})\n",
    "\n",
    "\n",
    "\tdef extract_other(self, chapter, header, section_text):\n",
    "\t\tself.categorized_data[\"Other\"].append({\"criteria\": f\"{header}\\n{section_text}\", \"chapter\": chapter})\n",
    "\n",
    "\tdef extract_data(self):\n",
    "\t\tchapter_text = Path(self.file_path).read_text(encoding=\"utf-8\")\n",
    "\t\tchapter = extract_chapter_title(chapter_text).strip()\n",
    "\t\tsection_list = extract_sections_list(chapter_text)\n",
    "\t\t\n",
    "\t\tfor index, (header, body) in enumerate(section_list):\n",
    "\t\t\theader = header.strip().lower()\n",
    "\t\t\tbody = body.strip()\n",
    "\t\t\tif header == \"criteria\":\n",
    "\t\t\t\tself.extract_critiera(chapter, body)\n",
    "\t\t\telif header == \"emergency response\":\n",
    "\t\t\t\tself.extract_scenario(chapter, body)\n",
    "\t\t\t# else:\n",
    "\t\t\t# \tself.extract_other(chapter, header, body)\n",
    "\n",
    "\t\t#print(json.dumps(self.categorized_data, indent=4, ensure_ascii=False))\n",
    "\n",
    "\tdef save_data(self, categorized_data=None):\n",
    "\t\tself.categorized_data = categorized_data if categorized_data else self.categorized_data\n",
    "\t\tself.formatted_data = []\n",
    "\n",
    "\t\twith open(f\"Data/Json/Unique/Chap_{self.base_name}.jsonl\", \"w\") as f_out:\n",
    "\t\t\tfor category, extractions in self.categorized_data.items():\n",
    "\t\t\t\tfor entry in extractions:\n",
    "\t\t\t\t\tunique_id = str(uuid.uuid4())\n",
    "\t\t\t\t\tcriteria = entry[\"criteria\"]\n",
    "\t\t\t\t\tchapter = entry[\"chapter\"]\n",
    "\t\t\t\t\tadvices = entry.get(\"advices\", None)\n",
    "\n",
    "\t\t\t\t\ttransformed_entry = [\n",
    "\t\t\t\t\t\t{\"role\": \"user\", \"content\": criteria, \"uuid\": unique_id, \"category\": category},\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\"role\": \"assistant\",\n",
    "\t\t\t\t\t\t\t\"content\": chapter,\n",
    "\t\t\t\t\t\t\t\"advices\": advices\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\t\tf_out.write(\n",
    "\t\t\t\t\t\tjson.dumps({\"entry\": transformed_entry}, ensure_ascii=False) + \"\\n\"\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t#print(f\"Saved Chap_{self.base_name}.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and generate QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/41 files.\n",
      "Processed 2/41 files.\n",
      "Processed 3/41 files.\n",
      "Processed 4/41 files.\n",
      "Processed 5/41 files.\n",
      "Processed 6/41 files.\n",
      "Processed 7/41 files.\n",
      "Processed 8/41 files.\n",
      "Processed 9/41 files.\n",
      "Processed 10/41 files.\n",
      "Processed 11/41 files.\n",
      "Processed 12/41 files.\n",
      "Processed 13/41 files.\n",
      "Processed 14/41 files.\n",
      "Processed 15/41 files.\n",
      "Processed 16/41 files.\n",
      "Processed 17/41 files.\n",
      "Processed 18/41 files.\n",
      "Processed 19/41 files.\n",
      "Processed 20/41 files.\n",
      "Processed 21/41 files.\n",
      "Processed 22/41 files.\n",
      "Processed 23/41 files.\n",
      "Processed 24/41 files.\n",
      "Processed 25/41 files.\n",
      "Processed 26/41 files.\n",
      "Processed 27/41 files.\n",
      "Processed 28/41 files.\n",
      "Processed 29/41 files.\n",
      "Processed 30/41 files.\n",
      "Processed 31/41 files.\n",
      "Processed 32/41 files.\n",
      "Processed 33/41 files.\n",
      "Processed 34/41 files.\n",
      "Processed 35/41 files.\n",
      "Processed 36/41 files.\n",
      "Processed 37/41 files.\n",
      "Processed 38/41 files.\n",
      "Processed 39/41 files.\n",
      "Processed 40/41 files.\n",
      "Processed 41/41 files.\n"
     ]
    }
   ],
   "source": [
    "file_paths = [\"Data/LabelWork/\" + file for file in os.listdir(\"Data/LabelWork\")]\n",
    "file_paths.sort()\n",
    "for i, file_path in enumerate(file_paths):\n",
    "\tdata_object = ExtractData(file_path=file_path)\n",
    "\tdata_object.extract_data()\n",
    "\tdata_object.save_data()\n",
    "\tprint(f\"Processed {i+1}/{len(file_paths)} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parser = JsonOutputParser()\n",
    "\n",
    "\n",
    "Paraphrase_Count = 12\n",
    "\n",
    "expanded_criteria_queries = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "### SYSTEM:\n",
    "You are a medical language model working strictly within a clinical and emergency dispatch context. \n",
    "The following inputs are part of a dataset used for emergency medical protocols. It may contain references to trauma, injuries, or sensitive conditions, but these are strictly medical and not graphic, explicit, or abusive.\n",
    "Given a chapter and a situation, your task is to generate medically accurate, varied and diverse keyword-style paraphrases that express the same idea using different terminology and phrasing.\n",
    "\n",
    "### Goals:\n",
    "- Capture **diverse wording** and structure without changing meaning.\n",
    "- Include **all symptoms**, **demographic indicators** (e.g., adult, child, infant, teen), and **context** (e.g., trauma, CPR-trained, location/environment).\n",
    "- The **chapter** should be reflected **implicitly** through phrasing, not stated directly.\n",
    "- This diversity improves **model generalization** during training, so prioritize **variety and uniqueness** in phrasing.\n",
    "\n",
    "### Style:\n",
    "- Use **short fragments**, separated by commas or keywords.\n",
    "- Avoid full sentences.\n",
    "- Each paraphrase must retain the **intent, medical significance, and critical details**.\n",
    "\n",
    "### INSTRUCTIONS:\n",
    "- Ensure each paraphrase is unique in terms and structure and wording to help the model **generalize** better.\n",
    "- Each paraphrase must retain critical medical meaning while varying language significantly.\n",
    "- Avoid just reordering words; use synonyms, alternate symptom phrasing, and alternate demographic framing.\n",
    "- \n",
    "\n",
    "Chapter: \"{Chapter}\"\n",
    "Situation: \"{Situation}\"\n",
    "\n",
    "Response Format:\n",
    "```json\n",
    "{{\n",
    "  \"Paraphrases\": [],\n",
    "}}\n",
    "```\n",
    "\n",
    "### IMPORTANT:\n",
    "- Return a JSON object with exactly one key: \"Paraphrases\" containing {Paraphrase_Count} UNIQUE, keyword-based paraphrases that express the same medical situation with diverse wording, capturing all symptoms, demographics, and context from the input chapter and situation.\n",
    "- Do not use latex or markdown formatting in your answer.\n",
    "- Do not follow the example verbatim; use it as a guide an apply the same logic to the new chapter and situation.\n",
    "\"\"\",\n",
    "    input_variables=[\"Chapter\", \"Situation\", \"Paraphrase_Count\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateParaphraseData():\n",
    "\tdef __init__(self, file_path):\n",
    "\t\tself.retries = 3\n",
    "\t\tself.file_path = file_path\n",
    "\t\tself.base_name = Path(file_path).stem\n",
    "\t\tself.formatted_data = []\n",
    "\t\tself.categorized_data = {\n",
    "\t\t\t\"Criteria\": [],\n",
    "\t\t}\n",
    "\n",
    "\tdef expand_criteria(self, Chapter, Situation):\n",
    "\t\t# Try with o1 model first\n",
    "\t\tfor i in range(self.retries):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tllm = init_chat_model(**settings.processmodel.o1.model_dump(exclude_none=True))\n",
    "\t\t\t\tchain = expanded_criteria_queries | llm | StrOutputParser()\n",
    "\t\t\t\tresponse = chain.invoke({\"Chapter\": Chapter, \"Situation\": Situation, \"Paraphrase_Count\": Paraphrase_Count})\n",
    "\t\t\t\tobject = json_parser.parse(response.strip())\n",
    "\n",
    "\t\t\t\tif len(object[\"Paraphrases\"]) != Paraphrase_Count:\n",
    "\t\t\t\t\tprint(f\"- Warning: Less than {Paraphrase_Count} paraphrases generated. Retrying... ({i+1}/{self.retries})\")\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\treturn object[\"Paraphrases\"]\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(f\"- Error: {e}\")\n",
    "\t\t\tfinally:\n",
    "\t\t\t\tif llm is not None:\n",
    "\t\t\t\t\tdel llm\n",
    "\n",
    "\t\t# Retry with gpt4o model\n",
    "\t\tprint(\"- Warning: Retrying with gpt4o model...\")\n",
    "\t\ttry:\n",
    "\t\t\tllm = init_chat_model(**settings.processmodel.gpt4o.model_dump(exclude_none=True))\n",
    "\t\t\tchain = expanded_criteria_queries | llm | StrOutputParser()\n",
    "\t\t\tresponse = chain.invoke({\"Chapter\": Chapter, \"Situation\": Situation, \"Paraphrase_Count\": Paraphrase_Count})\n",
    "\t\t\tobject = json_parser.parse(response.strip())\n",
    "\n",
    "\t\t\tif len(object[\"Paraphrases\"]) != Paraphrase_Count:\n",
    "\t\t\t\traise Exception(f\"Less than {Paraphrase_Count} paraphrases generated.\")\n",
    "\t\t\t\n",
    "\t\t\treturn object[\"Paraphrases\"]\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"- Error: {e}\")\n",
    "\t\tfinally:\n",
    "\t\t\tif llm is not None:\n",
    "\t\t\t\tdel llm\n",
    "\n",
    "\t\t# Retry with deepseek model\n",
    "\t\tprint(\"- Warning: Retrying with deepseek model...\")\n",
    "\t\ttry:\n",
    "\t\t\tllm = init_chat_model(**settings.processmodel.deepseek.model_dump(exclude_none=True))\n",
    "\t\t\tchain = expanded_criteria_queries | llm | StrOutputParser()\n",
    "\t\t\tcot_response = chain.invoke({\"Chapter\": Chapter, \"Situation\": Situation, \"Paraphrase_Count\": Paraphrase_Count})\n",
    "\t\t\tresponse = re.sub(r\"<think>.*?</think>\", \"\", cot_response, flags=re.DOTALL).strip()\n",
    "\t\t\tobject = json_parser.parse(response.strip())\n",
    "\n",
    "\t\t\tif len(object[\"Paraphrases\"]) != Paraphrase_Count:\n",
    "\t\t\t\traise Exception(f\"Less than {Paraphrase_Count} paraphrases generated.\")\n",
    "\n",
    "\t\t\treturn object[\"Paraphrases\"]\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"- Error: {e}\")\n",
    "\t\tfinally:\n",
    "\t\t\tif llm is not None:\n",
    "\t\t\t\tdel llm\n",
    "\n",
    "\t\t# Retry with phi4 model\n",
    "\t\tprint(\"- Warning: Retrying with phi4 model...\")\n",
    "\t\ttry:\n",
    "\t\t\tllm = init_chat_model(**settings.processmodel.phi4.model_dump(exclude_none=True))\n",
    "\t\t\tchain = expanded_criteria_queries | llm | StrOutputParser()\n",
    "\t\t\tresponse = chain.invoke({\"Chapter\": Chapter, \"Situation\": Situation, \"Paraphrase_Count\": Paraphrase_Count})\n",
    "\t\t\tobject = json_parser.parse(response.strip())\n",
    "\n",
    "\t\t\tif len(object[\"Paraphrases\"]) != Paraphrase_Count:\n",
    "\t\t\t\traise Exception(f\"Less than {Paraphrase_Count} paraphrases generated.\")\n",
    "\t\t\treturn object[\"Paraphrases\"]\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"- Error: {e}\")\n",
    "\t\tfinally:\n",
    "\t\t\tif llm is not None:\n",
    "\t\t\t\tdel llm\n",
    "\n",
    "\t\tprint(\"- Error: All models failed to generate paraphrases.\")\n",
    "\n",
    "\n",
    "\tdef extract_critiera(self, chapter, section_text):\n",
    "\t\tcriteria_list = TRAIN_get_criteria_advices(section_text)\n",
    "\t\tfor i, entry in enumerate(criteria_list):\n",
    "\t\t\tunique_id = str(uuid.uuid4())\n",
    "\t\t\tcriterion = entry[\"criteria\"]\n",
    "\t\t\tadvices = f\"# Relevant Chapters:\\n- {chapter}\\n\" + \"\\n\".join(entry[\"advice_list\"])\n",
    "\t\t\tparaphrases = self.expand_criteria(chapter, criterion)\n",
    "\t\t\tfor criteria in paraphrases:\n",
    "\t\t\t\tself.categorized_data[\"Criteria\"].append({\"criteria\": criteria,  \"uuid\": unique_id, \"advices\": advices, \"chapter\": chapter})\n",
    "\n",
    "\tdef extract_data(self):\n",
    "\t\tchapter_text = Path(self.file_path).read_text(encoding=\"utf-8\")\n",
    "\t\tchapter = extract_chapter_title(chapter_text).strip()\n",
    "\t\tsection_list = extract_sections_list(chapter_text)\n",
    "\t\tfor index, (header, body) in enumerate(section_list):\n",
    "\t\t\theader = header.strip().lower()\n",
    "\t\t\tbody = body.strip()\n",
    "\t\t\tif header == \"criteria\":\n",
    "\t\t\t\tself.extract_critiera(chapter, body)\n",
    "\n",
    "\tdef save_data(self, categorized_data=None):\n",
    "\t\tself.categorized_data = categorized_data if categorized_data else self.categorized_data\n",
    "\t\tself.formatted_data = []\n",
    "\n",
    "\t\twith open(f\"Data/Json/Paraphrase/Chap_{self.base_name}.jsonl\", \"w\") as f_out:\n",
    "\t\t\tfor category, extractions in self.categorized_data.items():\n",
    "\t\t\t\tfor entry in extractions:\n",
    "\t\t\t\t\tunique_id = entry[\"uuid\"]\n",
    "\t\t\t\t\tcriteria = entry[\"criteria\"]\n",
    "\t\t\t\t\tchapter = entry[\"chapter\"]\n",
    "\t\t\t\t\tadvices = entry.get(\"advices\", None)\n",
    "\n",
    "\t\t\t\t\ttransformed_entry = [\n",
    "\t\t\t\t\t\t{\"role\": \"user\", \"content\": criteria, \"uuid\": unique_id, \"category\": category},\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\"role\": \"assistant\",\n",
    "\t\t\t\t\t\t\t\"content\": chapter,\n",
    "\t\t\t\t\t\t\t\"advices\": advices\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\t\tf_out.write(\n",
    "\t\t\t\t\t\tjson.dumps({\"entry\": transformed_entry}, ensure_ascii=False) + \"\\n\"\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t#print(f\"Saved Chap_{self.base_name}.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/41 files.\n",
      "Processed 2/41 files.\n",
      "Processed 3/41 files.\n",
      "Processed 4/41 files.\n",
      "Processed 5/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "Processed 6/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 7/41 files.\n",
      "Processed 8/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 9/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "Processed 10/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 11/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "Processed 12/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 13/41 files.\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (3/3)\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Less than 12 paraphrases generated.\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 14/41 files.\n",
      "Processed 15/41 files.\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (3/3)\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Less than 12 paraphrases generated.\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (3/3)\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Less than 12 paraphrases generated.\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 16/41 files.\n",
      "Processed 17/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "Processed 18/41 files.\n",
      "Processed 19/41 files.\n",
      "Processed 20/41 files.\n",
      "Processed 21/41 files.\n",
      "Processed 22/41 files.\n",
      "Processed 23/41 files.\n",
      "Processed 24/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 25/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (3/3)\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Less than 12 paraphrases generated.\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 26/41 files.\n",
      "Processed 27/41 files.\n",
      "Processed 28/41 files.\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (3/3)\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Less than 12 paraphrases generated.\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 29/41 files.\n",
      "Processed 30/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "Processed 31/41 files.\n",
      "Processed 32/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "Processed 33/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 34/41 files.\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 35/41 files.\n",
      "Processed 36/41 files.\n",
      "Processed 37/41 files.\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "Processed 38/41 files.\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (3/3)\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Less than 12 paraphrases generated.\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Error: Azure has not provided the response due to a content filter being triggered\n",
      "Processed 39/41 files.\n",
      "Processed 40/41 files.\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (3/3)\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Less than 12 paraphrases generated.\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (3/3)\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Less than 12 paraphrases generated.\n",
      "- Warning: Retrying with deepseek model...\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (1/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (2/3)\n",
      "- Warning: Less than 12 paraphrases generated. Retrying... (3/3)\n",
      "- Warning: Retrying with gpt4o model...\n",
      "- Error: Less than 12 paraphrases generated.\n",
      "- Warning: Retrying with deepseek model...\n",
      "Processed 41/41 files.\n"
     ]
    }
   ],
   "source": [
    "file_paths = [\"Data/LabelWork/\" + file for file in os.listdir(\"Data/LabelWork\")]\n",
    "file_paths.sort()\n",
    "for i, file_path in enumerate(file_paths):\n",
    "\tdata_object = GenerateParaphraseData(file_path=file_path)\n",
    "\tdata_object.extract_data()\n",
    "\tdata_object.save_data()\n",
    "\tprint(f\"Processed {i+1}/{len(file_paths)} files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
