{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6bb7b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a description of a situation, you must identify the most relevant chapter from the provided list ONLY.\n",
      "You MUST strictly select exactly one chapter from the list below. Do NOT invent, paraphrase, abbreviate, or modify any chapter titles.\n",
      "\n",
      "Here are the chapters to select from (enclosed within the <start_chapters> and <end_chapters> tags):\n",
      "<start_chapters>\n",
      "- 03 Unconscious / decreased level of consciousness, breathing normally\n",
      "- 04 Choking / foreign object\n",
      "- 05 Mental health issue\n",
      "- 06 Mental health crisis - suicide risk\n",
      "- 07 Burns\n",
      "- 08 Drowning\n",
      "- 09 Scuba diving accident\n",
      "- 10 Chemicals / gasses / CBRN\n",
      "- 11 Accident / injury\n",
      "- 12 Major incident\n",
      "- 13 Road traffic accident - RTA\n",
      "- 14 Violence / abuse\n",
      "- 15 Allergic reaction\n",
      "- 16 Child / infant - illness\n",
      "- 17 Bite / insect sting\n",
      "- 18 Bleeding - non-traumatic\n",
      "- 19 Chest pain / cardiac disease\n",
      "- 20 Diabetes\n",
      "- 22 Fever / infection / sepsis\n",
      "- 23 Poisoning - not related to alcohol or drugs\n",
      "- 24 Functional decline\n",
      "- 25 Childbirth\n",
      "- 26 Gynecology / pregnancy\n",
      "- 27 Stroke symptoms\n",
      "- 28 Headache\n",
      "- 29 Skin / rash\n",
      "- 30 Hyperthermia / heat stroke / heat exhaustion\n",
      "- 31 Hypothermia / cold person\n",
      "- 32 Seizures (convulsions, fits)\n",
      "- 33 Breathing problems\n",
      "- 34 Drug abuse / intoxication / overdose\n",
      "- 35 Pain in the abdomen / back / extremities\n",
      "- 37 Urinary tract\n",
      "- 38 Ear, nose and throat\n",
      "- 39 Eye\n",
      "<end_chapters>\n",
      "\n",
      "Response format is STRICTLY required as follows (Follow this format exactly with no deviations):\n",
      "# Chapter:\n",
      "- [chapter number] [chapter title]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_chapter(text):\n",
    "\ttext = re.sub(r'#', '', text) # Remove hashtags\n",
    "\treturn text.strip()\n",
    "\n",
    "def extract_chapter_title(content):\n",
    "    pattern = r\"^#\\s*(.+)$\"\n",
    "    for i, line in enumerate(content.split(\"\\n\"), start=1):\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "start_index = 2\n",
    "end_index = -3\n",
    "exclude = np.array([21, 36])\n",
    "exclude-=1\n",
    "\n",
    "file_paths = [\"Data/LabelWork/\" + file for file in os.listdir(\"Data/LabelWork\")]\n",
    "file_paths.sort()\n",
    "\n",
    "resolved_end = len(file_paths) + end_index if end_index < 0 else end_index\n",
    "indices = [i for i in range(start_index, resolved_end) if i not in exclude.tolist()]\n",
    "sliced_paths = [file_paths[i] for i in indices]\n",
    "\n",
    "chapter_list = []\n",
    "for file_path in sliced_paths:\n",
    "    chapter_text = Path(file_path).read_text(encoding=\"utf-8\")\n",
    "    chapter = extract_chapter_title(chapter_text).strip()\n",
    "    chapter_list.append(clean_chapter(chapter))\n",
    "\n",
    "chapters = \"- \" + \"\\n- \".join(chapter_list)\n",
    "\n",
    "\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"Given a description of a situation, you must identify the most relevant chapter from the provided list ONLY.\\n\"\n",
    "        \"You MUST strictly select exactly one chapter from the list below. Do NOT invent, paraphrase, abbreviate, or modify any chapter titles.\\n\\n\"\n",
    "        \"Here are the chapters to select from (enclosed within the <start_chapters> and <end_chapters> tags):\\n\"\n",
    "        \"<start_chapters>\\n\"\n",
    "        f\"{chapters}\\n\"\n",
    "        \"<end_chapters>\\n\\n\"\n",
    "        \"Response format is STRICTLY required as follows (Follow this format exactly with no deviations):\\n\"\n",
    "        \"# Chapter:\\n\"\n",
    "        \"- [chapter number] [chapter title]\"\n",
    "       \n",
    "    )\n",
    "}\n",
    "\n",
    "print(system_message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7d30ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 SUPER. Num GPUs = 1. Max memory: 11.836 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "bs = 4\n",
    "lr = 5e-4\n",
    "epochs = 1\n",
    "wd = 0.001\n",
    "log_steps = 500\n",
    "gradient_accumulation_steps = 1\n",
    "rank = 16\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0\n",
    "max_seq_length = 1024\n",
    "model_name = \"unsloth/Qwen3-4B-unsloth-bnb-4bit\"\n",
    "\n",
    "param_str = f\"-LORA-(ep={epochs}, bs={bs}, lr={lr}, grad_acc={gradient_accumulation_steps}, wd={wd}, rank={rank}, lora_alpha={lora_alpha}, lora_dropout={lora_dropout}, log_steps={log_steps})\"\n",
    "output_dir = f\"./Models/{model_name.replace('/','-')}\" + param_str\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = torch.bfloat16,\n",
    "    load_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086cc3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = rank,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = lora_alpha,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = lora_dropout, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = seed,\n",
    "    use_rslora = False,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8ab3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 10465\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1136\n",
      "})\n",
      "Training for 1 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2617"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "\n",
    "def extract_relevant_chapters(text):\n",
    "    # Use a regex to capture the header line plus any following lines starting with '- '\n",
    "    match = re.search(r\"(# Relevant Chapters:\\s*\\n(?:- .*\\n?)*)\", text)\n",
    "    if match:\n",
    "        # Return the matched group (header + chapter lines)\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_first_number(text):\n",
    "\tmatch = re.search(r'\\b\\d+\\b', text)\n",
    "\tif match:\n",
    "\t\treturn match.group().strip()\n",
    "\treturn \"\"\n",
    "\n",
    "# Training\n",
    "train_intra = load_dataset(\"json\", data_files=\"Data/TrainData/intra_chapter_dataset.jsonl\",split=\"train\")\n",
    "train_paraphrase = load_dataset(\"json\", data_files=\"Data/TrainData/paraphrase_dataset.jsonl\",split=\"train\")\n",
    "train_dataset = concatenate_datasets([train_intra, train_paraphrase])\n",
    "\n",
    "# Validation\n",
    "val_intra = load_dataset(\"json\", data_files=\"Data/ValData/intra_chapter_dataset.jsonl\",split=\"train\")\n",
    "val_paraphrase = load_dataset(\"json\", data_files=\"Data/ValData/paraphrase_dataset.jsonl\",split=\"train\")\n",
    "val_dataset = concatenate_datasets([val_intra, val_paraphrase])\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "\tconvos = examples[\"QandA\"]\n",
    "\n",
    "\tfor i, convo in enumerate(convos):\n",
    "\t\t\n",
    "\t\t# Check for exactly 2 messages (usually system + assistant)\n",
    "\t\tif len(convo) != 2:\n",
    "\t\t\traise ValueError(f\"Expected exactly 2 messages in conversation, found {len(convo)}: {convo}\")\n",
    "\n",
    "\t\t# Validate that user input (message 0) doesn't contain chapter predictions\n",
    "\t\tif \"relevant chapters\" in convo[0][\"content\"].lower():\n",
    "\t\t\traise ValueError(f\"Unexpected 'relevant chapters' in the first message: {convo[0]['content']}\")\n",
    "\t\t\n",
    "\t\t# Extract and clean relevant chapter section from assistant message\n",
    "\t\tchapter_text = extract_relevant_chapters(convo[1][\"content\"])\n",
    "\t\tif not chapter_text:\n",
    "\t\t\traise ValueError(f\"Relevant chapter section not found in: {convo[1]['content']}\")\n",
    "\t\t\n",
    "\t\t# Verify chapter number is present\n",
    "\t\tif extract_first_number(chapter_text) == \"\":\n",
    "\t\t\traise ValueError(f\"Chapter number not found in: {chapter_text}\")\n",
    "\t\t\n",
    "\t\t# Replace the assistant message with the cleaned chapter string\n",
    "\t\tconvos[i][1][\"content\"] = re.sub(r\"#\\s*Relevant Chapters\\s*:\", \"# Chapter:\", chapter_text)\n",
    "\n",
    "\n",
    "\ttexts = [\n",
    "\t\ttokenizer.apply_chat_template([system_message] + convo, tokenize = False, add_generation_prompt = False)\n",
    "\t\tfor convo in convos\n",
    "\t]\n",
    "\treturn {\"text\": texts}\n",
    "\t\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True).remove_columns([\"QandA\"])\n",
    "val_dataset = val_dataset.map(formatting_prompts_func, batched=True).remove_columns([\"QandA\"])\n",
    "\n",
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "\n",
    "\n",
    "print(f\"Training for {epochs} epochs\")\n",
    "steps_per_epoch = np.ceil(len(train_dataset) / (bs * gradient_accumulation_steps))\n",
    "target_steps = int(steps_per_epoch * epochs)\n",
    "target_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731ef50",
   "metadata": {},
   "source": [
    "#### Ensuring each example is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f6b440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Given a description of a situation, you must identify the most relevant chapter from the provided list ONLY.\n",
      "You MUST strictly select exactly one chapter from the list below. Do NOT invent, paraphrase, abbreviate, or modify any chapter titles.\n",
      "\n",
      "Here are the chapters to select from (enclosed within the <start_chapters> and <end_chapters> tags):\n",
      "<start_chapters>\n",
      "- 03 Unconscious / decreased level of consciousness, breathing normally\n",
      "- 04 Choking / foreign object\n",
      "- 05 Mental health issue\n",
      "- 06 Mental health crisis - suicide risk\n",
      "- 07 Burns\n",
      "- 08 Drowning\n",
      "- 09 Scuba diving accident\n",
      "- 10 Chemicals / gasses / CBRN\n",
      "- 11 Accident / injury\n",
      "- 12 Major incident\n",
      "- 13 Road traffic accident - RTA\n",
      "- 14 Violence / abuse\n",
      "- 15 Allergic reaction\n",
      "- 16 Child / infant - illness\n",
      "- 17 Bite / insect sting\n",
      "- 18 Bleeding - non-traumatic\n",
      "- 19 Chest pain / cardiac disease\n",
      "- 20 Diabetes\n",
      "- 22 Fever / infection / sepsis\n",
      "- 23 Poisoning - not related to alcohol or drugs\n",
      "- 24 Functional decline\n",
      "- 25 Childbirth\n",
      "- 26 Gynecology / pregnancy\n",
      "- 27 Stroke symptoms\n",
      "- 28 Headache\n",
      "- 29 Skin / rash\n",
      "- 30 Hyperthermia / heat stroke / heat exhaustion\n",
      "- 31 Hypothermia / cold person\n",
      "- 32 Seizures (convulsions, fits)\n",
      "- 33 Breathing problems\n",
      "- 34 Drug abuse / intoxication / overdose\n",
      "- 35 Pain in the abdomen / back / extremities\n",
      "- 37 Urinary tract\n",
      "- 38 Ear, nose and throat\n",
      "- 39 Eye\n",
      "<end_chapters>\n",
      "\n",
      "Response format is STRICTLY required as follows (Follow this format exactly with no deviations):\n",
      "# Chapter:\n",
      "- [chapter number] [chapter title]<|im_end|>\n",
      "<|im_start|>user\n",
      "Fatigued, lethargic, post-dive, reduced alertness, unresponsive state post-scuba dive, loss of consciousness, immediate dive-related unconsciousness<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "# Chapter: \n",
      "- 09 Scuba diving accident<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in train_dataset:\n",
    "\tif \"# Chapter:\" not in example[\"text\"] and extract_first_number(example[\"text\"]) != \"\":\n",
    "\t\traise ValueError(f\"Found 'relevant chapters' in training data: {example['text']}\")\n",
    "\t\n",
    "print(train_dataset[100][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005bdbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "from unsloth import unsloth_train\n",
    "\n",
    "class CustomSFTTrainer(SFTTrainer):\n",
    "\tdef __init__(self, *args, **kwargs):\n",
    "\t\tsuper().__init__(*args, **kwargs)\n",
    "\t\tself.train_losses = [] \n",
    "\t\tself.eval_losses = []\n",
    "\n",
    "\tdef log(self, logs, *args, **kwargs):\n",
    "\t\tif \"loss\" in logs:\n",
    "\t\t\tself.train_losses.append(logs[\"loss\"])\n",
    "\n",
    "\t\tif \"eval_loss\" in logs:\n",
    "\t\t\tself.eval_losses.append(logs[\"eval_loss\"])\n",
    "\n",
    "\t\tsuper().log(logs, *args, **kwargs)\n",
    "\n",
    "\tdef get_train_losses(self):\n",
    "\t\treturn self.train_losses\n",
    "\t\n",
    "\tdef get_eval_losses(self):\n",
    "\t\treturn self.eval_losses\n",
    "\n",
    "\n",
    "trainer = CustomSFTTrainer(\n",
    "\tpacking = False, # Can make training 5x faster for short sequences.\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "\teval_dataset = val_dataset,\n",
    "    args = SFTConfig(\n",
    "\t\tlogging_steps = log_steps,\n",
    "\t\teval_strategy=\"steps\",\n",
    "\t\teval_steps=log_steps,\n",
    "\t\tseed = seed,\n",
    "        weight_decay = wd,\n",
    "        learning_rate = lr, \n",
    "\n",
    "        num_train_epochs=epochs,\n",
    "\t\t#max_steps=target_steps,\n",
    "        \n",
    "\t\tper_device_train_batch_size = bs,\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps, # Use GA to mimic batch size!\n",
    "        warmup_steps = 10,\n",
    "\t\tbf16 = True,\n",
    "        dataset_text_field = \"text\",\n",
    "        optim = \"adamw_8bit\",\n",
    "        lr_scheduler_type = \"linear\",\n",
    "\t\tsave_strategy=\"no\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295316f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4070 SUPER. Max memory = 11.836 GB.\n",
      "4.207 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0d70f",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a77129cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 10,465 | Num Epochs = 1 | Total steps = 2,617\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 33,030,144/4,000,000,000 (0.83% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2617' max='2617' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2617/2617 53:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.279091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.253875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.275452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.271457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.274872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n",
      "Model saved to ./Models/unsloth-Qwen3-4B-unsloth-bnb-4bit-LORA-(ep=1, bs=4, lr=0.0005, grad_acc=1, wd=0.001, rank=16, lora_alpha=16, lora_dropout=0, log_steps=500)\n",
      "./Data/Plots/unsloth-Qwen3-4B-unsloth-bnb-4bit-LORA-(ep=1, bs=4, lr=0.0005, grad_acc=1, wd=0.001, rank=16, lora_alpha=16, lora_dropout=0, log_steps=500).json\n",
      "Losses saved to ./Data/Plots/unsloth-Qwen3-4B-unsloth-bnb-4bit-LORA-(ep=1, bs=4, lr=0.0005, grad_acc=1, wd=0.001, rank=16, lora_alpha=16, lora_dropout=0, log_steps=500).json\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = unsloth_train(trainer)\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n",
    "\n",
    "train_losses = trainer.get_train_losses()\n",
    "eval_losses = trainer.get_eval_losses()\n",
    "\n",
    "losses_dict = {\n",
    "\t\"train_losses\": train_losses,\n",
    "\t\"eval_losses\": eval_losses\n",
    "}\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "losses_file_path = f\"./Data/Plots/{model_name.replace('/','-')}\" + param_str + \".json\"\n",
    "\n",
    "print(losses_file_path)\n",
    "with open(losses_file_path, 'w') as f:\n",
    "\tjson.dump(losses_dict, f, indent=2)\n",
    "print(f\"Losses saved to {losses_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95728f",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1c4724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 SUPER. Num GPUs = 1. Max memory: 11.836 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen3ForCausalLM(\n",
       "      (model): Qwen3Model(\n",
       "        (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (2): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (3): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (4): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (5): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (6): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (7-32): 26 x Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (33): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (34): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "          (35): Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9728, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9728, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    " \n",
    "#model_path = \"Models/unsloth-Qwen3-4B-unsloth-bnb-4bit-LORA-(ep=1, bs=4, lr=0.0005, grad_acc=1, wd=0.001, rank=8, lora_alpha=8, lora_dropout=0, log_steps=500)\"\n",
    "model_path = \"Models/unsloth-Qwen3-4B-unsloth-bnb-4bit-LORA-(ep=1, bs=4, lr=0.0005, grad_acc=1, wd=0.001, rank=16, lora_alpha=16, lora_dropout=0, log_steps=500)\"\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name = model_path,\n",
    "\tmax_seq_length = 1024,\n",
    "\tdtype = torch.bfloat16,\n",
    "\tload_in_4bit = True,\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcdc1ea",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb8e6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "# Chapter:\n",
      "- 11 Accident / injury"
     ]
    }
   ],
   "source": [
    "from transformers import TextIteratorStreamer\n",
    "import threading\n",
    "\n",
    "streamer = TextIteratorStreamer(\n",
    "    tokenizer,\n",
    "    skip_prompt=True,\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "user_query = \"\"\"\n",
    "Fell down from height, injured leg and bleeding\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    system_message,\n",
    "    {\"role\" : \"user\", \"content\" : user_query}\n",
    "]\n",
    "\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = True, # Disable thinking\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Start generation in a separate thread\n",
    "generation_thread = threading.Thread(target=model.generate, kwargs={\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    \"streamer\": streamer,\n",
    "    \"max_new_tokens\": 20,\n",
    "    \"use_cache\": True,\n",
    "    \"do_sample\": False,\n",
    "\t# \"temperature\": 0.7, \n",
    "    # \"top_p\": 0.8, \n",
    "    # \"top_k\": 20,\n",
    "})\n",
    "generation_thread.start()\n",
    "\n",
    "# Capture output\n",
    "captured_output = \"\"\n",
    "for token in streamer:\n",
    "    print(token, end=\"\", flush=True)\n",
    "    captured_output += token\n",
    "    \n",
    "generation_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d23516c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Chapter:\n",
      "- 14 Violence / abuse<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "def clean_response(text):\n",
    "\ttext = re.split(r\"<\\|im_start\\|>assistant\\n?\", text)\n",
    "\ttext = text[-1] if len(text) > 1 else text\n",
    "\treturn re.sub(r\"</?\\|?think\\|?>\", \"\", text).strip()\n",
    "\n",
    "# User query\n",
    "user_query = \"\"\"\n",
    "So I went to visit my cousin today to find him down on the ground unable to get up. His head was seriously bleeding alot. What should I do with all the blood?\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "\tsystem_message,\n",
    "\t{\"role\": \"user\", \"content\": user_query}\n",
    "]\n",
    "\n",
    "# Prepare the chat prompt\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "\tmessages,\n",
    "\ttokenize=False,\n",
    "\tadd_generation_prompt=True,\n",
    "\tenable_thinking=True,\n",
    ")\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate response\n",
    "outputs = model.generate(\n",
    "\t**inputs,\n",
    "\tmax_new_tokens=128,\n",
    "\tdo_sample=False,\n",
    "\tuse_cache=True\n",
    ")\n",
    "\n",
    "# Decode and extract only the assistant response\n",
    "decoded = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "# Clean thinktags and print\n",
    "print(clean_response(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d53bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/erik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/erik/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/erik/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "f1_metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44f73e",
   "metadata": {},
   "source": [
    "Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd4170f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d71b8d17de40e09aa7190227192c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1136 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 1136\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "test_intra = load_dataset(\"json\", data_files=\"Data/TestData/intra_chapter_dataset.jsonl\", split=\"train\")\n",
    "test_paraphrase = load_dataset(\"json\", data_files=\"Data/TestData/paraphrase_dataset.jsonl\", split=\"train\")\n",
    "test_dataset = concatenate_datasets([test_intra, test_paraphrase])\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "\tconvos = examples[\"QandA\"]\n",
    "\ttexts = []\n",
    "\tlabels = []\n",
    "\tfor convo in convos:\n",
    "\t\t# Remove assistant messages\n",
    "\t\tfiltered_convo = [msg for msg in convo if msg[\"role\"] != \"assistant\"]\n",
    "\t\tlabel = [msg[\"content\"] for msg in convo if msg[\"role\"] == \"assistant\"][0]\n",
    "\n",
    "\t\tinstruct_convo = [system_message] + filtered_convo\n",
    "\n",
    "\t\t# Format using the template\n",
    "\t\ttext = tokenizer.apply_chat_template(\n",
    "\t\t\tinstruct_convo,\n",
    "\t\t\ttokenize=False,\n",
    "\t\t\tadd_generation_prompt=True,\n",
    "\t\t\tenable_thinking=False,\n",
    "\t\t)\n",
    "\t\ttexts.append(text)\n",
    "\t\tlabels.append(label)\n",
    "\treturn {\"text\": texts, \"labels\": labels} \n",
    "\t\n",
    "test_dataset = test_dataset.map(formatting_prompts_func, batched=True).remove_columns([\"QandA\"])\n",
    "\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188f462",
   "metadata": {},
   "source": [
    "Vague dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488f7b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74bb4d839f04cddbc8a6159f2fc077a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 35\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"json\", data_files=\"Data/TestData/vague_data.jsonl\", split=\"train\")\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "\ttexts = []\n",
    "\tlabels = []\n",
    "\tfor input_text, label in zip(examples[\"input_text\"], examples[\"label\"]):\n",
    "\t\tmessages = [\n",
    "\t\t\tsystem_message,\n",
    "\t\t\t{\"role\": \"user\", \"content\": input_text}\n",
    "\t\t]\n",
    "\n",
    "\t\ttext = tokenizer.apply_chat_template(\n",
    "\t\t\tmessages,\n",
    "\t\t\ttokenize=False,\n",
    "\t\t\tadd_generation_prompt=True,\n",
    "\t\t\tenable_thinking=False,\n",
    "\t\t)\n",
    "\n",
    "\t\ttexts.append(text)\n",
    "\t\tlabels.append(str(label))\n",
    "\treturn {\"text\": texts, \"labels\": labels} \n",
    "\t\n",
    "test_dataset = test_dataset.map(formatting_prompts_func, batched=True).remove_columns([\"input_text\", \"label\"])\n",
    "\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0694fddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Given a description of a situation, you must identify the most relevant chapter from the provided list ONLY.\n",
      "You MUST strictly select exactly one chapter from the list below. Do NOT invent, paraphrase, abbreviate, or modify any chapter titles.\n",
      "\n",
      "Here are the chapters to select from (enclosed within the <start_chapters> and <end_chapters> tags):\n",
      "<start_chapters>\n",
      "- 03 Unconscious / decreased level of consciousness, breathing normally\n",
      "- 04 Choking / foreign object\n",
      "- 05 Mental health issue\n",
      "- 06 Mental health crisis - suicide risk\n",
      "- 07 Burns\n",
      "- 08 Drowning\n",
      "- 09 Scuba diving accident\n",
      "- 10 Chemicals / gasses / CBRN\n",
      "- 11 Accident / injury\n",
      "- 12 Major incident\n",
      "- 13 Road traffic accident - RTA\n",
      "- 14 Violence / abuse\n",
      "- 15 Allergic reaction\n",
      "- 16 Child / infant - illness\n",
      "- 17 Bite / insect sting\n",
      "- 18 Bleeding - non-traumatic\n",
      "- 19 Chest pain / cardiac disease\n",
      "- 20 Diabetes\n",
      "- 22 Fever / infection / sepsis\n",
      "- 23 Poisoning - not related to alcohol or drugs\n",
      "- 24 Functional decline\n",
      "- 25 Childbirth\n",
      "- 26 Gynecology / pregnancy\n",
      "- 27 Stroke symptoms\n",
      "- 28 Headache\n",
      "- 29 Skin / rash\n",
      "- 30 Hyperthermia / heat stroke / heat exhaustion\n",
      "- 31 Hypothermia / cold person\n",
      "- 32 Seizures (convulsions, fits)\n",
      "- 33 Breathing problems\n",
      "- 34 Drug abuse / intoxication / overdose\n",
      "- 35 Pain in the abdomen / back / extremities\n",
      "- 37 Urinary tract\n",
      "- 38 Ear, nose and throat\n",
      "- 39 Eye\n",
      "<end_chapters>\n",
      "\n",
      "Response format is STRICTLY required as follows (Follow this format exactly with no deviations):\n",
      "# Chapter:\n",
      "- [chapter number] [chapter title]<|im_end|>\n",
      "<|im_start|>user\n",
      "Condition: Patient is knocked out and not responding, but his respiration looks okay though\n",
      "Observations: Lying halfway off the couch, one shoe missing, staring but not reacting much, made a soft noise once, room was stuffy and warm\n",
      "Cause: No idea â€” just noticed something was off when they didn't answer the doorbell<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9c94fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Batched Evaluation (Inference) on Test Data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:11<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference results saved to ./Data/Evaluation/NewVagueTestModels-unsloth-Qwen3-4B-unsloth-bnb-4bit-LORA-(ep=1, bs=4, lr=0.0005, grad_acc=1, wd=0.001, rank=16, lora_alpha=16, lora_dropout=0, log_steps=500).json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from tqdm import tqdm  \n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "input_texts = []\n",
    "references = []\n",
    "predictions = []\n",
    "\n",
    "def extract_first_number(text):\n",
    "\tmatch = re.search(r'\\b\\d+\\b', text)\n",
    "\tif match:\n",
    "\t\treturn match.group().strip()\n",
    "\treturn \"\"\n",
    "\n",
    "def clean_response(text):\n",
    "\ttext = re.split(r\"<\\|im_start\\|>assistant\\n?\", text)\n",
    "\ttext = text[-1] if len(text) > 1 else text\n",
    "\ttext = re.sub(r\"</?\\|?vision_pad\\|?>\", \"\", text).strip()\n",
    "\treturn re.sub(r\"</?\\|?think\\|?>\", \"\", text).strip()\n",
    "\n",
    "for entry in test_dataset:\n",
    "\tinput_text = entry[\"text\"]\n",
    "\tlabel = entry[\"labels\"]\n",
    "\tinput_texts.append(input_text)\n",
    "\treferences.append(extract_first_number(label.strip()))\n",
    "\n",
    "\n",
    "# Create batches manually\n",
    "dataloader = DataLoader(list(zip(input_texts, references)), batch_size=BATCH_SIZE)\n",
    "\n",
    "# Run inference\n",
    "for batch in tqdm(dataloader, desc=\"Running Batched Evaluation (Inference) on Test Data\"):\n",
    "\tbatch_input_texts, batch_labels = batch\n",
    "\t\n",
    "\t# Tokenize\n",
    "\tinputs = tokenizer(list(batch_input_texts), padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\t# Generate response\n",
    "\twith torch.no_grad():\n",
    "\t\toutputs = model.generate(\n",
    "\t\t\t**inputs,\n",
    "\t\t\tmax_new_tokens=20,\n",
    "\t\t\tdo_sample=False,\n",
    "\t\t\tuse_cache=True\n",
    "\t\t)\n",
    "\n",
    "\tbatch_text = []\n",
    "\tbatch_numbers = []\n",
    "\tdecoded_texts = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
    "\tfor decoded_text in decoded_texts:\n",
    "\t\tresponse = clean_response(decoded_text)\n",
    "\t\tbatch_text.append(response)\n",
    "\t\tbatch_numbers.append(extract_first_number(response))\n",
    "\t\tpredictions.append(extract_first_number(response))\n",
    "\n",
    "\tif \"\" in batch_numbers:\n",
    "\t\tdisplay(batch_text)\n",
    "\t\tprint(batch_numbers)\n",
    "\t\traise ValueError(\"Empty chapter number found in batch predictions.\")\n",
    "\t\n",
    "\n",
    "\n",
    "# Prepare data for saving\n",
    "output_data = {\n",
    "    \"references\": references,\n",
    "    \"predictions\": predictions\n",
    "}\n",
    "\n",
    "# Save the data to a JSON file\n",
    "output_file = \"./Data/Evaluation/NewVagueTest\" + model_path.replace(\"./Models/\",\"\").replace(\"/\", \"-\") + \".json\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f\"Inference results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
